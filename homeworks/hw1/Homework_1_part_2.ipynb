{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpO92YkQ-9SB"
   },
   "source": [
    "# ДЗ 1, часть 2. Теория информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имя, Фамилия: *напишите здесь*\n",
    "\n",
    "группа: *напишите здесь группу, где вы числитесь*\n",
    "\n",
    "**Оценка(для проверяющего):** 0 из 10\n",
    "\n",
    "**Дедлайн:** одновременно с частью 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all imports here please\n",
    "import pickle as pkl\n",
    "\n",
    "from collections import OrderedDict\n",
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#... add your own if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Энтропию можно использовать не только для описания хаотичности, беспорядочности и уровня неопределённости, но и для того, чтобы исследовать зависимость между случайными величинами, используя теорию информации. Начнём с базовых вещей и постепенно дойдём до ультрапопулярной эвристики выбора важных признаков для машинного обучения -- взаимной информации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4hbID4f_ZW7"
   },
   "source": [
    "## Задача 1. Поисследуем энтропию (2 балла)\n",
    "\n",
    "Будем предполагать, что нам даны две случайных величины $X,Y$, можете предполагать, что они дискретные или имеют плотности, выкладок этот факт не изменит, но делайте всё по одному стандарту: укажите ниже и придерживайтесь его на всём протяжении ДЗ, если явно не просят сделать иначе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose your weapon/Выберите ваше оружие/Сhoisissez votre arme/Изаберите себи оружje:**  \n",
    "\n",
    "$$\n",
    "\\int .. dx  ~~  \\text{или} ~~ \\sum_i  ~~\\text{(выберите одно)}\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jU9QZbW0_gJi"
   },
   "source": [
    "### Независимость?\n",
    "\n",
    "Покажите, что если две случайных величины $X,Y$ независимы, то $H(X,Y)=H(X)+H(Y)$.\n",
    "\n",
    "Имейте в виду, что слева под знаком энтропии ДВЕ случайных величины, рассматриваемых как 2d-вектор, поэтому матожидание берётся по их совместному закону распределения. Это называется *совместной энтропией* величин $X,Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШЕ РЕШЕНИЕ И ОБОСНОВАНИЯ ТУТ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зависимость?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите, что в общем случае\n",
    "\n",
    "$$\n",
    "H(X,Y) = H(X) + H(Y \\vert X)\n",
    "$$\n",
    "и вычислите, чему будет равен остаток $H(Y \\vert X)$. Он носит название *условной энтропии*, не путайте с энтропией условного распределения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШЕ РЕШЕНИЕ И ОБОСНОВАНИЯ ТУТ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!! Обоснуйте, какой может быть физический смысл $H(Y\\vert X)$ (что она измеряет?) с точки зрения теории кодирования в случае дискретных СВ $X,Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШ КОММЕНТАРИЙ ТУТ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDNXyjtgAdnv"
   },
   "source": [
    "## Задача 2. Взаимная информация (2 балла)\n",
    "\n",
    "Можно рассмотреть разницу\n",
    "\n",
    "$$\n",
    "I(X,Y) = H(X) - H(X \\vert Y),\n",
    "$$\n",
    "\n",
    "которая отражает в некотором смысле (вы наверняка об этом думали в окошке выше) уровень использования информации о значении $Y$ при кодировании $X$ (если мы о кодировании). Эта величина носит название *взаимной информации* и является ещё одним хорошим способом исследования зависимости между случайными величинами. Библиотека `sklearn` позволяет оценивать её по данным и тем самым выделять самые важные признаки для моделей машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aMyr0QdAdnw"
   },
   "source": [
    "### Симметричность\n",
    "\n",
    "Докажите, что $I(X,Y)=I(Y,X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШЕ РЕШЕНИЕ И ОБОСНОВАНИЯ ТУТ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Связь с KL\n",
    "\n",
    "Докажите, что $I(X,Y)= D_{KL}( p_{X,Y} \\vert p_{X}p_{Y})$. Слева совместное распределение $X,Y$, справа -- произведение вероятностей(или плотностей) $X,Y$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd6AICLiAdnx"
   },
   "source": [
    "ВАШЕ РЕШЕНИЕ И ОБОСНОВАНИЯ ТУТ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какой смысл?..\n",
    "\n",
    "Как вы думаете, как интерпретируется $I(X,Y)$ в терминах теории кодирования (при дискретных $X,Y$)? Что измеряет эта величина?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШ КОММЕНТАРИЙ ТУТ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Максимальная энтропия (3 балла)\n",
    "\n",
    "### Экспоненциальное распределение\n",
    "\n",
    "(1 балл) Вычислите энтропию для экспоненциального распределения $Exp(\\lambda)$ и распределения Лапласа $Laplace(0,\\lambda)$, имеющее плотность $\\frac{\\lambda}{2} e^{-\\lambda \\vert x\\vert }$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШЕ РЕШЕНИЕ И ОБОСНОВАНИЯ ТУТ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(2 балла) Докажите, что Экспоненциальное распределение $Exp(\\lambda)$ имеет максимальную энтропию среди всех абсолютно непрерывных вероятностных распределений с фиксированным средним и имеющих ненулевую плотность в области $x\\geq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШЕ РЕШЕНИЕ И ОБОСНОВАНИЯ ТУТ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим свой код, основанный на частотах (3 балла)\n",
    "\n",
    "Представим себе для примера достаточно большую книгу (например, Войну и Мир Льва Николаевича Толстого). Для того, чтобы записывать буквы в кодировке UTF-8 требуется от 2 до 4 байт (каждый 8бит). Но книга -- это не просто какой-то iid равновероятный поток символов, а структурированный текст, структуру которого можно по-разному использовать. К примеру, мы можем задуматься над тем, чтобы сжать её, используя информацию о том, какие символы встречаются чаще: ведь более частые можно кодировать более короткими кодовыми словами, а более редкие -- более длинными.\n",
    "\n",
    "В этом идея [кода Хаффмана](https://compression.ru/download/articles/huff/huffman_1952_minimum-redundancy-codes.pdf), который мы попробуем поисследовать в самой простой наивной имплементации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисляем языковую статистику\n",
    "\n",
    "Возьмём для примера текст вики-страницы [МО1](http://wiki.cs.hse.ru/%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"moText.txt\",\"r\", encoding=\"utf-8\") as f:\n",
    "    MOText = \"\\n\".join(f.readlines())\n",
    "\n",
    "print(MOText[:180])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это не сильно большой, но не очень маленький текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(MOText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислите частоту каждого символа, сохранив их в упорядоченный словарь (OrderedDict, пригодится для сортировок)  вида {<символ>: <частота>}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute OrderedDict\n",
    "#symFreqs = #YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in symFreqs.items():\n",
    "    print(f\"{key}: {val}\")\n",
    "print(f\"In total {len(symFreqs)} unique symbols, max freq= {max([val for val in symFreqs.values()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим Кодер и Декодер Хаффмана"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это хорошее упражнение для ценителей алгоритмов, но давайте сократим себе время и попробуем адаптировать одну из [доступных реализаций](https://www.geeksforgeeks.org/huffman-coding-in-python/) под наш сценарий, обернув в привычную классовую структуру и сохранив максимальную представленность самого алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from https://www.geeksforgeeks.org/huffman-coding-in-python/\n",
    "class Node:\n",
    "    def __init__(self, symbol=None, frequency=None):\n",
    "        #print(\"CREATING\", symbol, frequency)\n",
    "        self.symbol = symbol\n",
    "        self.frequency = frequency\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.frequency < other.frequency\n",
    "\n",
    "def build_huffman_tree(chars, freq):\n",
    "  \n",
    "    # Create a priority queue of nodes\n",
    "    priority_queue = [Node(char, f) for char, f in zip(chars, freq)]\n",
    "    heapq.heapify(priority_queue)\n",
    "\n",
    "    # Build the Huffman tree\n",
    "    while len(priority_queue) > 1:\n",
    "        left_child = heapq.heappop(priority_queue)\n",
    "        right_child = heapq.heappop(priority_queue)\n",
    "        merged_node = Node(frequency=left_child.frequency + right_child.frequency)\n",
    "        merged_node.left = left_child\n",
    "        merged_node.right = right_child\n",
    "        heapq.heappush(priority_queue, merged_node)\n",
    "\n",
    "    return priority_queue[0]\n",
    "\n",
    "def generate_huffman_codes(node, code=\"\", huffman_codes={}):\n",
    "    if node is not None:\n",
    "        if node.symbol is not None:\n",
    "            huffman_codes[node.symbol] = code\n",
    "        else:\n",
    "            generate_huffman_codes(node.left, code + \"0\", huffman_codes)\n",
    "            generate_huffman_codes(node.right, code + \"1\", huffman_codes)\n",
    "\n",
    "    return huffman_codes\n",
    "\n",
    "def runTest():\n",
    "    # Given example (try it to test)\n",
    "    chars = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "    freq = [4, 7, 15, 17, 22, 42]\n",
    "\n",
    "    # Build the Huffman tree\n",
    "    root = build_huffman_tree(chars, freq)\n",
    "\n",
    "    # Generate Huffman codes\n",
    "    huffman_codes = generate_huffman_codes(root)\n",
    "\n",
    "    # Print Huffman codes\n",
    "    for char, code in huffman_codes.items():\n",
    "        print(f\"Character: {char}, Code: {code}\")\n",
    "        \n",
    "runTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Надеемся, что этот код заработал.... Теперь напишем кодер, используя эту технологию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuffmanCoderDecoder:\n",
    "    \n",
    "    def __init__(self,symbolProbaTable):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbolProbaTable (dict): a dict with symbol(keys) and probabilities (val)\n",
    "        \"\"\" \n",
    "        self.symbols = list(symbolProbaTable.keys())\n",
    "        self.probas = list(symbolProbaTable.values())\n",
    "        self.symbolProbaTable = symbolProbaTable\n",
    "        self.root = None\n",
    "        self.fit()\n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Sets up encoder and decoder tables\n",
    "        \"\"\"        \n",
    "        #YOUR CODE....\n",
    "        #self.encoderTable = YOUR CODE (dict)\n",
    "        #self.decoderTable = YOUR CODE (dict)\n",
    "        pass\n",
    "        \n",
    "    def encode(self, text):\n",
    "        \"\"\"Encodes the text and returns encoded text\n",
    "\n",
    "        Args:\n",
    "            text (str): text to encode\n",
    "        Returns:\n",
    "            encodedText (str): encoded text\n",
    "        \"\"\"\n",
    "        #YOUR CODE....\n",
    "        pass        \n",
    "        #return ....\n",
    "    \n",
    "    def decode(self, text):\n",
    "        \"\"\"Decodes the encoded text and returns decoded text\n",
    "\n",
    "        Args:\n",
    "            text (str): text to decode\n",
    "        Returns:\n",
    "            decodedText (str): decoded text\n",
    "        \"\"\" \n",
    "        #YOUR CODE....\n",
    "        pass        \n",
    "        #return ....       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textSample = MOText[:200]\n",
    "\n",
    "#Create coder\n",
    "huff = HuffmanCoderDecoder(symFreqs)\n",
    "#Encode text\n",
    "#YOUR CODE\n",
    "encText = \n",
    "#decode text to check if it works\n",
    "#YOUR CODE\n",
    "decText = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислите, какое получилось сжатие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compression(%): \",len(textSample.encode('utf-8'))*8/len(encText)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поздравляем, вы сделали простой алгоритм сжатия) .... если у вас больше 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследуем, как хорошо себя ведёт код при смене текста\n",
    "\n",
    "Сравните написанный кодер на двух понравившихся вам текстах на разные темы (возьмите по масштабу что-то похожее на страницу МО).\n",
    "\n",
    "1. Для чистоты эксперимента очистите оба текста от символов, которых нет в другом тексте\n",
    "2. Посчитайте таблицу частот для каждого из текстов\n",
    "3. Обучите кодер на тексте 1\n",
    "4. Обучите кодер на тексте 2\n",
    "5. Сопоставьте длину (в битах): \n",
    "   1. Текст1, закодированный кодером 1\n",
    "   2. Текст2, закодированный кодером 1\n",
    "   3. Текст1, закодированный кодером 2\n",
    "   4. Текст2, закодированный кодером 2\n",
    "6. Посчитайте KL-дивергенцию и кроссэнтропию в обе стороны между частотами кодера1 и кодера2\n",
    "\n",
    "Прокомментируйте результат.\n",
    "\n",
    "Не забудьте приложить к решению ваших два текстовых файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"<YOURTEXT1>.txt\",\"r\", encoding=\"utf-8\") as f:\n",
    "    text1 = \"\\n\".join(f.readlines())\n",
    "with open(\"<YOURTEXT2>.txt\",\"r\", encoding=\"utf-8\") as f:\n",
    "    text2 = \"\\n\".join(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR PROCESSING\n",
    "###......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f\"KL(text1 | text2)={yourResult}\" )\n",
    "print( f\"KL(text2 | text1)={yourResult}\" )\n",
    "print( f\"CE(text1 | text2)={yourResult}\" )\n",
    "print( f\"CE(text2 | text1)={yourResult}\" )\n",
    "print( f\"H(text1)={yourResult}\" )\n",
    "print( f\"H(text2)={yourResult}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Coding with text1: text1Len={yourResult}, text2Len={yourResult}\") \n",
    "print(f\"Coding with text2: text1Len={yourResult}, text2Len={yourResult}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD A CHART like https://matplotlib.org/stable/gallery/lines_bars_and_markers/barchart.html\n",
    "#and draw distributions of text1 and text2\n",
    "#f, ax = plt.subplots\n",
    "#...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШИ КОММЕНТАРИИ ЗДЕСЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZGDzE6YO9zYe",
    "g4hbID4f_ZW7",
    "ZDNXyjtgAdnv",
    "75QeT2ShA1KU"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
