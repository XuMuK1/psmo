{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNXqKgEGz1b7"
   },
   "source": [
    "# Теория информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GiW-VYxlHpx"
   },
   "source": [
    "## Терминология"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBtqRv7wlKga"
   },
   "source": [
    "Множество возможных исходов события $\\quad I = \\{ e_1, ... e_m \\}$.\n",
    "\n",
    "**Событие** (в смысле случайная величина)  $\\quad E: \\Omega \\to I$.\n",
    "\n",
    "Вероятности происхождения событий: $\\quad p_j = \\mathbb{P}(E = e_j)$.\n",
    "\n",
    "**Алфавит кодера** $\\quad J = \\{0, ..., q-1\\}$.\n",
    "\n",
    "**Кодовое слово** события $e_j$ -- строка $x_1...x_{s_j} = f(i_j)$,  \n",
    "\n",
    "где  $ f: I \\to \\cup_{n \\geq 1}   J^n$ называют **кодом**.\n",
    "\n",
    "**Длина случайного кодового слова** -- это случайная величина $len(f(E))$.\n",
    "\n",
    "**Средняя длина кодового слова** -- это $\\mathbb{E}[S] = \\sum \\limits_{j=1}^m p_j s_j$.\n",
    "\n",
    "**Энтропия** распределения $\\quad H_q(p_1, ... p_m) = \\sum \\limits_{j=1}^m p_j ( -\\log_q p_j)$ (в непрерывном случае -- интеграл).\n",
    "\n",
    "**Кросс-энтропия** из $p'$ в $p$ -- это  $\\quad CE(p|p') = \\sum \\limits_{j=1}^m p_j ( -\\log_q p'_j)$ (в непрерывном случае -- интеграл).\n",
    "\n",
    "**KL-дивергенция** из $p'$ в $p$ -- это $\\quad D_{KL} (p|p') = CE(p|p') - H(p)$ (в непрерывном случае -- c интегралами)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPcEvsP6FKFq"
   },
   "source": [
    "## Пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-lPqEXaH7Hq"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1694685518766,
     "user": {
      "displayName": "Дарья Демидова",
      "userId": "17379068568578483334"
     },
     "user_tz": -180
    },
    "id": "QkUmFNU0H-ac",
    "outputId": "0c2c7329-5892-465e-fe13-1c269cadcd42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.shopify.com/s/files/1/1014/5789/files/Standard-ASCII-Table_large.jpg?10669400161723642407\" width=\"400\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_url = 'https://cdn.shopify.com/s/files/1/1014/5789/files/Standard-ASCII-Table_large.jpg?10669400161723642407'\n",
    "Image(url=img_url, width=400, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvHrqSrVFLfA"
   },
   "source": [
    "$I = \\{e_1, ... e_m \\} = \\{ \\text{NULL}, ..., \\sim, \\text{DEL} \\}$ - множество символов клавиатуры\n",
    "\n",
    "$E$ - случайный символ клавиатуры\n",
    "\n",
    "$p_j = \\mathbb{P}(E = e_j)$ - частота использования символа $e_j$\n",
    "\n",
    "$J = \\{0,1,2,...9, \\text{A,B,C,D,F} \\}$ - алфавит кодера\n",
    "\n",
    "$f: e_j \\in I \\to x_1 ... x_{s_j} \\in \\cup_{n \\geq 1}   J^n$ - кодирование символа $i_j$ клавиатуры бинарным кодом $x_1 ... x_{s_j}$\n",
    "\n",
    "$f(+) = 2\\text{B}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHxtaKFhS_sM"
   },
   "source": [
    "## Мотивация\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bNLIcOMTAnE"
   },
   "source": [
    "$l(\\theta) = \\ln p_{\\theta}(\\hat{X})$ - правдободобие для фиксированно выборки $\\hat{X} = \\{ \\hat{X}_1, ... \\hat{X}_n \\}$\n",
    "\n",
    "Выборка $\\hat{X} = \\{ \\hat{X}_1, ... \\hat{X}_n \\}$ - это реализация случайной величины $X = \\{X_1, ..., X_n \\} \\sim p_{\\theta_0}(x_1, ..., x_n)$\n",
    "\n",
    "$\\tilde{l}(\\theta, X) = \\ln p_{\\theta}(X)$ - правдободобие для случайной выборки $X = \\{X_1, ..., X_n \\}$\n",
    "\n",
    "$\\mathbb{E}_{X \\sim p_{\\theta_0}} \\tilde{l}(\\theta, X) = \\int p_{\\theta_0}(x) \\ln p_{\\theta}(x) dx = - CE(p_{\\theta_0} | p_{\\theta})$\n",
    "\n",
    "Таким образом, в контексте метода максимального правдоподобия возникает понятие кросс-энтропии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yAeXGH_K0cA"
   },
   "source": [
    "## Задача 1 (минимальная средняя длина)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AC34aFgL2qm1"
   },
   "source": [
    "$I = \\{A, B, C, D\\}$\n",
    "\n",
    "$p = \\{ \\frac12,\\frac14, \\frac18, \\frac18 \\}$\n",
    "\n",
    "$J = \\{0,1\\}$\n",
    "\n",
    "**Найти среднюю длину оптимального кода**\n",
    "\n",
    "Т.е., найти наименьшие $s_1, ... s_n$, такие, для которых существует $f: I \\to \\cup_{n \\geq 1}   J^n$ со следующем условием: символ $i_j$ кодируется строкой длины $s_j$.\n",
    "\n",
    "$q = 2$\n",
    "\n",
    "\n",
    "\n",
    "$\\min \\limits_{s1, ..., s_m} \\mathbb{E}[S] = \\min \\limits_{s1, ..., s_m} \\sum \\limits_{j=1}^m p_j s_j \\quad \\text{s.t.} \\quad \\sum \\limits_{j=1}^m  q^{-s_j} \\leq 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbIb6DQMLFk1"
   },
   "source": [
    "## Энтропия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wviEzNXvLH7R"
   },
   "source": [
    "Энтропия дискретного распределения $\\quad H_q(p_1, ... p_m) = \\sum \\limits_{j=1}^m p_j ( -\\log_q p_j) = \\sum \\limits_{j=1}^m p_j \\tilde{s}_j^{\\ast} = \\mathbb{E} \\tilde{S}^{\\ast}$\n",
    "\n",
    "Энтропия непрерывного распределения  $\\quad H(p) = \\int p(x) \\ln p(x) dx$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS7v8PMZj9ZA"
   },
   "source": [
    "## Теорема Шеннона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz2Art4hj_fH"
   },
   "source": [
    "$H_q(p) \\leq \\min \\limits_{s_j} \\mathbb{E}[S] \\leq H_q(p) + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRfbXS4oBqEh"
   },
   "source": [
    "Эквивалентно,\n",
    "\n",
    "$\\sum \\limits_{j=1}^m p_j ( -\\log_q p_j) \\leq \\sum \\limits_{j=1}^m p_j s_j^* \\leq \\sum \\limits_{j=1}^m p_j ( -\\log_q p_j) + 1$\n",
    "\n",
    "Или более сильное утверждение,\n",
    "\n",
    "$ -\\log_q p_j \\leq  s_j^* \\leq -\\log_q p_j + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbdQmHqRCHim"
   },
   "source": [
    "**Доказательство**\n",
    "\n",
    "Релаксируем задачу $\\min \\limits_{s1, ..., s_m} \\mathbb{E}[S] \\, \\text{s.t.} \\sum \\limits_{j=1}^m  q^{-s_j} \\leq 1$ на непрерывные переменные $\\tilde{s}_1, ... \\tilde{s}_m$.\n",
    "\n",
    "Решение методом Лагранжа дает $\\tilde{s}_j^* = - \\log_q p_j$.\n",
    "\n",
    "Взяв ближашие целые решения, получим $ -\\log_q p_j \\leq  s_j^* \\leq -\\log_q p_j + 1$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJoWy7t4Lb-Y"
   },
   "source": [
    "**Интерпретация энтропии**\n",
    "\n",
    "Энтропия - это оценка средней длины оптимального кода\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diLc6Yp_GhqN"
   },
   "source": [
    "## Кросс-энтропия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ18EDuOGlVs"
   },
   "source": [
    "Код $f : I \\to \\cup_{n \\geq 1}   J^n$ является оптимальным для распределения $p$ на $I$.\n",
    "\n",
    "Код $f' : I \\to \\cup_{n \\geq 1}   J^n$ является оптимальным для распределения $p'$ на $I$.\n",
    "\n",
    "Пусть $p$ - истинное распределение событий $I$, а $p'$ - ошибочное.\n",
    "\n",
    "Тогда энтропия $H_q(p) = \\sum \\limits_{j=1}^m p_j ( -\\log_q p_j)$ оценивает длину оптимального кода $f$, построенного по истинному распределению, а кросс-энтропия\n",
    "$CE(p|p') = \\sum \\limits_{j=1}^m p_j ( -\\log_q p'_j)$ оценивает длину какого-то кода $f'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyeQC-2SVr7a"
   },
   "source": [
    "$CE(p|p') \\leq \\min \\limits_{s'_j} \\mathbb{E}[S'] \\leq CE(p|p')  + 1$, где $S'$ - длина случайного кодового слова в кодировке $f'$, при этом вероятность случайного слова соответствует истинному распределению $p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNOQVYLoVpN_"
   },
   "source": [
    "**Доказательство**\n",
    "\n",
    "$  -\\log_q p'_j \\leq  s_j^{' \\ast} \\leq  -\\log_q p'_j + 1$.\n",
    "\n",
    "$\\sum \\limits_{j=1}^m p_j ( -\\log_q p'_j) \\leq \\sum \\limits_{j=1}^m p_j s_j^{' \\ast} \\leq  \\sum \\limits_{j=1}^m p_j ( -\\log_q p'_j) + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blQVRtzUW--b"
   },
   "source": [
    "## Задача 2 (свойства кросс-энтропии)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YVxxPMLXA2w"
   },
   "source": [
    "Доказать\n",
    "\n",
    "1. $CE(p|p) = H_q(p)$\n",
    "\n",
    "2. $CE(p|p') \\geq H_q(p)$  (неравенство Гибса, $D_{KL} \\geq 0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8B4Ub3c2NwG2"
   },
   "source": [
    "## Задача 3 (энтропия равномерного распределения)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwTt6hDM3q1f"
   },
   "source": [
    "$p = U\\{1,2,...,m \\}$ - равномерное распределение на дискретном множестве\n",
    "\n",
    "Найти $H_q(p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lREo9eBePNzO"
   },
   "source": [
    "## Задача 4 (энтропия нормального распределения)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpyHGGZMPTw6"
   },
   "source": [
    "Доказать, что распределение $\\mathcal{N}(\\mu, \\sigma^2)$ обладает максимальной энтропией в классе непрерывных распределений с матожиданием $\\mu$ и дисперсией $\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 5. (KL между нормальными распределениями)\n",
    "\n",
    "$$p =  \\mathcal{N}(\\mu_1, \\sigma_1^2)$$\n",
    "\n",
    "$$q =  \\mathcal{N}(\\mu_2, \\sigma_2^2)$$\n",
    "\n",
    "Найдите $D_{KL}(p \\vert q)$ (из $q$ в $p$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6MXdPo_IxqE"
   },
   "source": [
    "## Задача 6* (код Хаффмана)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECquQRLPJrRu"
   },
   "source": [
    "1. Построить оптимальный код (код Хаффмана) для $I = \\{A, B, C, D\\}$ и следующих вероятностей на $I$ : $p = \\{ \\frac12,\\frac14, \\frac18, \\frac18 \\}$, $p'$ равномерная.\n",
    "\n",
    "2. Посчитать соответствующие средние длины кодовых слов для $p$ и $p'$.\n",
    "\n",
    "3. Посчитать энтропиии для $p$ и $p'$.\n",
    "\n",
    "4. Посчитать кросс-энтропию $CE(p' | p)$ и $CE(p | p')$."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNRHsigXpx4HJuznWfibNfV",
   "collapsed_sections": [
    "cPcEvsP6FKFq",
    "xHxtaKFhS_sM",
    "v1VDGNFAO9CA",
    "fbIb6DQMLFk1",
    "OS7v8PMZj9ZA",
    "5qITqQn2Ki8t",
    "diLc6Yp_GhqN",
    "f6MXdPo_IxqE",
    "GUTRajKqty09",
    "blQVRtzUW--b",
    "PJXsUozf6yXB",
    "8B4Ub3c2NwG2",
    "e8XFTvqrnrTF",
    "lREo9eBePNzO",
    "QaVSobjSSne7"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
